{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Creating our Final Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Data used in this notebook can be found on the Kaggle competition page. Here is the description of the challenge (from Kaggle): \n",
    "\n",
    "Ask a home buyer to describe their dream house, and they probably won't begin with the height of the basement ceiling or the proximity to an east-west railroad. But this playground competition's dataset proves that much more influences price negotiations than the number of bedrooms or a white-picket fence.\n",
    "\n",
    "With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.\n",
    "\n",
    "(https://www.kaggle.com/c/house-prices-advanced-regression-techniques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, cross_val_score,StratifiedKFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.max_rows', None) \n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we create different models and check the cross validation score for them. Then we will optimize the model by tuning the hyperparameters. Using these models we blend them together to create the best possible model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Import and Randomize our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual, first we import the data and randomize it. Instead of splitting the dataset in training, testing, and validation data, we are just randomizing it. This is because during our hyperparameter tuning we will use Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import our Data\n",
    "\n",
    "data_location = 'housing_data_final.csv'\n",
    "df = pd.read_csv(data_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomize our Data an call K-fold to preform cross validation \n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df_X = df.drop(columns=['SalePrice'])\n",
    "df_y = df['SalePrice']\n",
    "\n",
    "kf = KFold(n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Implement and Tune Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use six different algorithms and run cross validation on them. This will optomoize our models hyperparameters. For each of the cell in this section (excluding the first one below this) remember to change the loop (and the model nested within it) too loop through the different hyperparameter variables.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function that does cross validation \n",
    "\n",
    "def cf_score(model, X, y):\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, \n",
    "                    scoring = \"neg_mean_squared_error\", cv = kf))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.12763245416656266, Std. Dev.: 0.008258263033702888\n"
     ]
    }
   ],
   "source": [
    "#Assses individuals models using cross validation \n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linear = LinearRegression()\n",
    "\n",
    "met = cf_score(linear, df_X, df_y)\n",
    "\n",
    "print(f'Mean: {np.mean(met)}, Std. Dev.: {np.std(met)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>mean</th>\n",
       "      <th>Std. Dev.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.127210</td>\n",
       "      <td>0.008001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.127081</td>\n",
       "      <td>0.007725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.127056</td>\n",
       "      <td>0.007483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.127077</td>\n",
       "      <td>0.007277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.5</td>\n",
       "      <td>0.127125</td>\n",
       "      <td>0.007100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.127188</td>\n",
       "      <td>0.006947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha      mean  Std. Dev.\n",
       "0  0.5    0.127210  0.008001 \n",
       "1  1.0    0.127081  0.007725 \n",
       "2  1.5    0.127056  0.007483 \n",
       "3  2.0    0.127077  0.007277 \n",
       "4  2.5    0.127125  0.007100 \n",
       "5  3.0    0.127188  0.006947 "
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HyperParameter tuning (Ridge)\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "alpha = [.5 ,1, 1.5, 2, 2.5, 3]\n",
    "\n",
    "score_mean = []\n",
    "score_std = []\n",
    "\n",
    "for a in alpha: \n",
    "    ridge = Ridge(alpha = a)\n",
    "    met = cf_score(ridge, df_X, df_y)\n",
    "    score_mean.append(np.mean(met))\n",
    "    score_std.append(np.std(met))\n",
    "    \n",
    "    \n",
    "scores = pd.DataFrame(data = {'alpha':alpha, 'mean':score_mean, 'Std. Dev.':score_std})\n",
    "                       \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0.15448835259628496\n",
      "0.1\n",
      "0.14006288175890852\n",
      "0.25\n",
      "0.13683913305493425\n",
      "0.5\n",
      "0.13835232634419464\n",
      "0.75\n",
      "0.1402230458485898\n",
      "auto\n",
      "0.14234795915104584\n",
      "None\n",
      "0.14234795915104584\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>mean</th>\n",
       "      <th>Std. Dev.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.154488</td>\n",
       "      <td>0.009900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.140063</td>\n",
       "      <td>0.010221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.136839</td>\n",
       "      <td>0.010007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.138352</td>\n",
       "      <td>0.010413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.140223</td>\n",
       "      <td>0.010363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>auto</td>\n",
       "      <td>0.142348</td>\n",
       "      <td>0.010165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>0.142348</td>\n",
       "      <td>0.010165</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  metric      mean  Std. Dev.\n",
       "0  1      0.154488  0.009900 \n",
       "1  0.1    0.140063  0.010221 \n",
       "2  0.25   0.136839  0.010007 \n",
       "3  0.5    0.138352  0.010413 \n",
       "4  0.75   0.140223  0.010363 \n",
       "5  auto   0.142348  0.010165 \n",
       "6  None   0.142348  0.010165 "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HyperParameter tuning (RandomForest)\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "n_est = [500, 750, 1000, 1250, 1500]\n",
    "max_depth = [5, 10, 15, 20, 25]\n",
    "min_samples_split = [2, 4, 5, 7, 10]\n",
    "max_features = [1, .1, .25, .5, .75, 'auto', None]\n",
    "\n",
    "score_mean = []\n",
    "score_std = []\n",
    "\n",
    "\n",
    "for i in max_features:  \n",
    "    rf = RandomForestRegressor(n_estimators=1000,\n",
    "                              max_depth=20,\n",
    "                              min_samples_split= 5,\n",
    "                              min_samples_leaf=1,\n",
    "                              max_features=.25, \n",
    "                              oob_score=True,\n",
    "                              random_state=42)\n",
    "\n",
    "    met=cf_score(rf, df_X, df_y)\n",
    "    score_mean.append(np.mean(met))\n",
    "    print(i)\n",
    "    print(np.mean(met))\n",
    "    score_std.append(np.std(met))\n",
    "    \n",
    "scores = pd.DataFrame(data = {'metric':max_features, 'mean':score_mean, 'Std. Dev.':score_std})\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.14455633 0.13561319 0.14502696 0.12949093 0.13560097]\n",
      "0.1\n",
      "[0.14277981 0.13535803 0.14136242 0.12752613 0.13329778]\n",
      "0.5\n",
      "[0.13862838 0.12718245 0.13835522 0.12378724 0.12939915]\n",
      "1\n",
      "[0.13623831 0.12481996 0.13651455 0.12320651 0.12978315]\n",
      "1.5\n",
      "[0.1365239  0.12136062 0.13866885 0.12345615 0.13224422]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>mean</th>\n",
       "      <th>Std. Dev.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.138058</td>\n",
       "      <td>0.005936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.136065</td>\n",
       "      <td>0.005554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.131470</td>\n",
       "      <td>0.006006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.130112</td>\n",
       "      <td>0.005556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.5</td>\n",
       "      <td>0.130451</td>\n",
       "      <td>0.006917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   metric      mean  Std. Dev.\n",
       "0  0.0     0.138058  0.005936 \n",
       "1  0.1     0.136065  0.005554 \n",
       "2  0.5     0.131470  0.006006 \n",
       "3  1.0     0.130112  0.005556 \n",
       "4  1.5     0.130451  0.006917 "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HyperParameter tuning (XGBRegressor)\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "learning_rate = [.05, .1, .2, .5, .75, 1]\n",
    "max_depth = [2,4,6,10,12]\n",
    "min_child_weight = [5,10,15,20]\n",
    "gamma = [0, .1, .6, 1]\n",
    "alpha = [0, .1, .5, 1, 1.5]\n",
    "#alpha = np.arange(1,7,2)\n",
    "\n",
    "score_mean = []\n",
    "std_mean = []\n",
    "\n",
    "for i in alpha:  ## change to alpha\n",
    "    xgb = XGBRegressor(learning_rate= .05,\n",
    "                           n_estimators=6000,\n",
    "                           max_depth= 12,\n",
    "                           min_child_weight=15,\n",
    "                           gamma=0,  \n",
    "                           objective='reg:squarederror',\n",
    "                           nthread=-1,\n",
    "                           seed=27,\n",
    "                           reg_alpha=i,\n",
    "                           random_state=42)\n",
    "    print(i)\n",
    "\n",
    "    met=cf_score(xgb, df_X, df_y)\n",
    "    score_mean.append(np.mean(met))\n",
    "    std_mean.append(np.std(met))\n",
    "    print(met)\n",
    "    \n",
    "scores = pd.DataFrame(data = {'metric':alpha, 'mean':score_mean, 'Std. Dev.':std_mean})  #change metric:gamma metric:alpha\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>mean</th>\n",
       "      <th>Std. Dev.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.127541</td>\n",
       "      <td>0.008252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.127250</td>\n",
       "      <td>0.008195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00010</td>\n",
       "      <td>0.127064</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00015</td>\n",
       "      <td>0.126961</td>\n",
       "      <td>0.008025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00020</td>\n",
       "      <td>0.126924</td>\n",
       "      <td>0.007894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.127033</td>\n",
       "      <td>0.007656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.00030</td>\n",
       "      <td>0.127161</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     alpha      mean  Std. Dev.\n",
       "0  0.00001  0.127541  0.008252 \n",
       "1  0.00005  0.127250  0.008195 \n",
       "2  0.00010  0.127064  0.008100 \n",
       "3  0.00015  0.126961  0.008025 \n",
       "4  0.00020  0.126924  0.007894 \n",
       "5  0.00025  0.127033  0.007656 \n",
       "6  0.00030  0.127161  0.007400 "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HyperParameter tuning (Lasso)\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "alpha = [.00001 ,.00005, .0001, .00015, .0002,.00025,.0003]\n",
    "\n",
    "score_mean = []\n",
    "score_std = []\n",
    "\n",
    "for a in alpha: \n",
    "    lasso = Lasso(alpha = a)\n",
    "    met = cf_score(lasso, df_X, df_y)\n",
    "    score_mean.append(np.mean(met))\n",
    "    score_std.append(np.std(met))\n",
    "    \n",
    "    \n",
    "scores = pd.DataFrame(data = {'alpha':alpha, 'mean':score_mean, 'Std. Dev.':score_std})\n",
    "                       \n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrics</th>\n",
       "      <th>mean</th>\n",
       "      <th>Std. Dev.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.133260</td>\n",
       "      <td>0.007918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.128798</td>\n",
       "      <td>0.007409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.129573</td>\n",
       "      <td>0.006936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.129769</td>\n",
       "      <td>0.006350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.130210</td>\n",
       "      <td>0.006291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0.131092</td>\n",
       "      <td>0.006231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0.131919</td>\n",
       "      <td>0.006767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0.131957</td>\n",
       "      <td>0.006701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>0.133149</td>\n",
       "      <td>0.006266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   metrics      mean  Std. Dev.\n",
       "0  2        0.133260  0.007918 \n",
       "1  3        0.128798  0.007409 \n",
       "2  4        0.129573  0.006936 \n",
       "3  5        0.129769  0.006350 \n",
       "4  6        0.130210  0.006291 \n",
       "5  7        0.131092  0.006231 \n",
       "6  8        0.131919  0.006767 \n",
       "7  9        0.131957  0.006701 \n",
       "8  10       0.133149  0.006266 "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#HyperParameter tuning (LGBMRegressor)\n",
    "\n",
    "\n",
    "from lightgbm import LGBMRegressor \n",
    "    \n",
    "    \n",
    "num_leaves = np.arange(2,11,1)\n",
    "n_estimators = np.arange(250,751,50)\n",
    "learning_rate = np.arange(.01, .35, .01)\n",
    "boosting_type = ['gbdt','dart','goss']\n",
    "\n",
    "\n",
    "score_mean = []\n",
    "score_std = []\n",
    "\n",
    "\n",
    "for i in num_leaves:\n",
    "    lgb = LGBMRegressor(boosting_type='gbdt',\n",
    "                                  num_leaves = 3,\n",
    "                                  n_estimators = 550,\n",
    "                                  learning_rate = .06)\n",
    "                    \n",
    "    met = cf_score(lgb, df_X, df_y)\n",
    "    score_mean.append(np.mean(met))\n",
    "    score_std.append(np.std(met))\n",
    "    \n",
    "    \n",
    "scores = pd.DataFrame(data = {'metrics':num_leaves, 'mean':score_mean, 'Std. Dev.':score_std})\n",
    "                       \n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Create a blended model, and assess our Models Training and Validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMRegressor \n",
    "from sklearn.linear_model import Lasso\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our model with our optimized hyperparameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create our Models based on optimized hyperparameter values \n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=1000,\n",
    "                           max_depth=20,\n",
    "                           min_samples_split=5,\n",
    "                           min_samples_leaf=1,\n",
    "                           max_features=.25,\n",
    "                           oob_score=True,\n",
    "                           random_state=42)\n",
    "\n",
    "ridge = Ridge(alpha = 1.5)\n",
    "\n",
    "linear = LinearRegression()\n",
    "\n",
    "xgb = XGBRegressor(learning_rate=.05,\n",
    "                    n_estimators=6000,\n",
    "                    max_depth=12,\n",
    "                    min_child_weight=15,\n",
    "                    gamma=0,\n",
    "                    objective='reg:squarederror',\n",
    "                    nthread=-1,\n",
    "                    seed=27,\n",
    "                    reg_alpha=1,\n",
    "                    random_state=42)\n",
    "\n",
    "\n",
    "lasso = Lasso(alpha = 0.0002)\n",
    "\n",
    "lgb = LGBMRegressor(boosting_type='gbdt',\n",
    "                    num_leaves = 3,\n",
    "                    n_estimators = 550,\n",
    "                    learning_rate = .06)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also reimport the data again, this time splitting them into trainng and validation datasets. This will be used to create the ideal blend for our final model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re-import data and randomize it again \n",
    "data_location = 'housing_data_final.csv'\n",
    "df = pd.read_csv(data_location)      \n",
    "\n",
    "df_X = df.drop(columns=['SalePrice'])\n",
    "df_y = df['SalePrice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomize data into training and validation sets\n",
    "rand_split = np.random.rand(len(df))  \n",
    "train_list = rand_split < 0.75\n",
    "valid_list = rand_split >= 0.75\n",
    "\n",
    "train_X = df_X[train_list]\n",
    "train_y = df_y[train_list]\n",
    "\n",
    "valid_X = df_X[valid_list]\n",
    "valid_y = df_y[valid_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below will be used to calculate the RMSLE score of our predictions. We will go through all the models in isolation and see how they preforms. In the end we will use our lists (created two cells below) to create a dataframe to find the best model blend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for rmsle\n",
    "def rmsle(model, X, y):\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(model.predict(X),y))\n",
    "    return rmse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty list that we will fill with model scores\n",
    "train_score_list = []\n",
    "valid_score_list = []\n",
    "name_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score = 0.06742138156613312\n",
      "valid score = 0.13924309949398544\n"
     ]
    }
   ],
   "source": [
    "#create models that will be blended together\n",
    "rf.fit(train_X, train_y) \n",
    "\n",
    "train_score = rmsle(rf, train_X, train_y)\n",
    "valid_score = rmsle(rf, valid_X, valid_y)\n",
    "\n",
    "print(f'train score = {train_score}')\n",
    "print(f'valid score = {valid_score}')\n",
    "\n",
    "name_list.append('rf')\n",
    "train_score_list.append(train_score)\n",
    "valid_score_list.append(valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score = 0.1175657886064351\n",
      "valid score = 0.1337759462181755\n"
     ]
    }
   ],
   "source": [
    "linear.fit(train_X, train_y) \n",
    "\n",
    "train_score = rmsle(linear, train_X, train_y)\n",
    "valid_score = rmsle(linear, valid_X, valid_y)\n",
    "\n",
    "print(f'train score = {train_score}')\n",
    "print(f'valid score = {valid_score}')\n",
    "\n",
    "name_list.append('linear')\n",
    "train_score_list.append(train_score)\n",
    "valid_score_list.append(valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score = 0.08047667781513794\n",
      "valid score = 0.13554007677774318\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(train_X, train_y) \n",
    "\n",
    "train_score = rmsle(xgb, train_X, train_y)\n",
    "valid_score = rmsle(xgb, valid_X, valid_y)\n",
    "\n",
    "print(f'train score = {train_score}')\n",
    "print(f'valid score = {valid_score}')\n",
    "\n",
    "name_list.append('xgb')\n",
    "train_score_list.append(train_score)\n",
    "valid_score_list.append(valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score = 0.11818933106390538\n",
      "valid score = 0.13362273781753262\n"
     ]
    }
   ],
   "source": [
    "ridge.fit(train_X, train_y) \n",
    "\n",
    "train_score = rmsle(ridge, train_X, train_y)\n",
    "valid_score = rmsle(ridge, valid_X, valid_y)\n",
    "\n",
    "print(f'train score = {train_score}')\n",
    "print(f'valid score = {valid_score}')\n",
    "\n",
    "name_list.append('ridge')\n",
    "train_score_list.append(train_score)\n",
    "valid_score_list.append(valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score = 0.11832332003151178\n",
      "valid score = 0.13319813799178432\n"
     ]
    }
   ],
   "source": [
    "lasso.fit(train_X, train_y) \n",
    "\n",
    "train_score = rmsle(lasso, train_X, train_y)\n",
    "valid_score = rmsle(lasso, valid_X, valid_y)\n",
    "\n",
    "print(f'train score = {train_score}')\n",
    "print(f'valid score = {valid_score}')\n",
    "\n",
    "name_list.append('lasso')\n",
    "train_score_list.append(train_score)\n",
    "valid_score_list.append(valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train score = 0.10447589741919013\n",
      "valid score = 0.13599208677279326\n"
     ]
    }
   ],
   "source": [
    "lgb.fit(train_X, train_y) \n",
    "\n",
    "train_score = rmsle(lgb, train_X, train_y)\n",
    "valid_score = rmsle(lgb, valid_X, valid_y)\n",
    "\n",
    "print(f'train score = {train_score}')\n",
    "print(f'valid score = {valid_score}')\n",
    "\n",
    "name_list.append('lgb')\n",
    "train_score_list.append(train_score)\n",
    "valid_score_list.append(valid_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get model predictions\n",
    "\n",
    "train_pred_rf = rf.predict(train_X)\n",
    "valid_pred_rf = rf.predict(valid_X)\n",
    "\n",
    "train_pred_ridge = ridge.predict(train_X)\n",
    "valid_pred_ridge = ridge.predict(valid_X)\n",
    "\n",
    "train_pred_linear = linear.predict(train_X)\n",
    "valid_pred_linear = linear.predict(valid_X)\n",
    "\n",
    "train_pred_lasso = lasso.predict(train_X)\n",
    "valid_pred_lasso = lasso.predict(valid_X)\n",
    "\n",
    "train_pred_xgb = xgb.predict(train_X)\n",
    "valid_pred_xgb = xgb.predict(valid_X)\n",
    "\n",
    "train_pred_lgb = lgb.predict(train_X)\n",
    "valid_pred_lgb = lgb.predict(valid_X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used to calculate the RMSLE score of the blended model. I wrote a nested loop to go through all several possible model blending combination in an attempt to find the best one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate blended model score\n",
    "def rmsle_blended(predict_list, percentage_list, y): \n",
    "    \n",
    "    sum_list = []\n",
    "    \n",
    "    for i,j in zip(predict_list, percentage_list):\n",
    "        sum_list.append(i*j)\n",
    "\n",
    "    sum_mat = np.array(sum_list)\n",
    "\n",
    "    pred = np.sum(sum_mat, axis = 0)\n",
    "    \n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(pred,y))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.10466490594687117, 0.12951802227212394)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_list = [train_pred_rf, train_pred_ridge, train_pred_linear, train_pred_xgb, train_pred_lgb, train_pred_lasso]\n",
    "valid_list = [valid_pred_rf, valid_pred_ridge, valid_pred_linear, valid_pred_xgb, valid_pred_lgb, valid_pred_lasso]\n",
    "percentage_list = [.1, .4, .2, .1, .1, .1]\n",
    "\n",
    "train_rmsle= rmsle_blended(train_list, percentage_list, train_y)\n",
    "valid_rmsle= rmsle_blended(valid_list, percentage_list, valid_y)\n",
    "\n",
    "train_rmsle, valid_rmsle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_1 = np.arange(.1,.91,.1)\n",
    "layer_2 = np.arange(.1,.91,.1)\n",
    "layer_3 = np.arange(.1,.91,.1)\n",
    "layer_4 = np.arange(.1,.91,.1)\n",
    "layer_5 = np.arange(.1,.91,.1)\n",
    "layer_6 = np.arange(.1,.91,.1)\n",
    "\n",
    "for i in layer_1:\n",
    "    for j in layer_2:\n",
    "        for k in layer_3:\n",
    "            for l in layer_4:\n",
    "                for m in layer_5:\n",
    "                    for n in layer_6:\n",
    "                        per_list = [i,j,k,l,m,n]\n",
    "                        name = '-'.join(str(\"{:.1f}\".format(e)) for e  in per_list)\n",
    "                        if name not in name_list and (i+j+k+l+m+n) == 1:\n",
    "                            train_rmsle= rmsle_blended(train_list, per_list, train_y)\n",
    "                            valid_rmsle= rmsle_blended(valid_list, per_list, valid_y)\n",
    "\n",
    "                            train_score_list.append(train_rmsle)\n",
    "                            valid_score_list.append(valid_rmsle)\n",
    "                            name_list.append(name)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Train Score</th>\n",
       "      <th>Valid Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.1-0.1-0.3-0.3-0.1-0.1</td>\n",
       "      <td>0.095994</td>\n",
       "      <td>0.128519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.1-0.2-0.2-0.3-0.1-0.1</td>\n",
       "      <td>0.096079</td>\n",
       "      <td>0.128575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.1-0.1-0.2-0.3-0.1-0.2</td>\n",
       "      <td>0.096120</td>\n",
       "      <td>0.128576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.2-0.1-0.3-0.2-0.1-0.1</td>\n",
       "      <td>0.094512</td>\n",
       "      <td>0.128612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.1-0.2-0.1-0.3-0.1-0.2</td>\n",
       "      <td>0.096219</td>\n",
       "      <td>0.128645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.1-0.3-0.1-0.3-0.1-0.1</td>\n",
       "      <td>0.096180</td>\n",
       "      <td>0.128647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.1-0.1-0.1-0.3-0.1-0.3</td>\n",
       "      <td>0.096265</td>\n",
       "      <td>0.128648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.2-0.1-0.2-0.2-0.1-0.2</td>\n",
       "      <td>0.094639</td>\n",
       "      <td>0.128663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.2-0.2-0.2-0.2-0.1-0.1</td>\n",
       "      <td>0.094599</td>\n",
       "      <td>0.128664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.1-0.1-0.2-0.2-0.2-0.2</td>\n",
       "      <td>0.098481</td>\n",
       "      <td>0.128700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.2-0.2-0.1-0.2-0.1-0.2</td>\n",
       "      <td>0.094739</td>\n",
       "      <td>0.128728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.2-0.1-0.1-0.2-0.1-0.3</td>\n",
       "      <td>0.094785</td>\n",
       "      <td>0.128729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.2-0.3-0.1-0.2-0.1-0.1</td>\n",
       "      <td>0.094700</td>\n",
       "      <td>0.128733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.1-0.1-0.4-0.2-0.1-0.1</td>\n",
       "      <td>0.100090</td>\n",
       "      <td>0.128738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.2-0.1-0.2-0.3-0.1-0.1</td>\n",
       "      <td>0.090611</td>\n",
       "      <td>0.128762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.1-0.1-0.3-0.2-0.1-0.2</td>\n",
       "      <td>0.100195</td>\n",
       "      <td>0.128763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.1-0.2-0.1-0.2-0.2-0.2</td>\n",
       "      <td>0.098581</td>\n",
       "      <td>0.128768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.1-0.2-0.3-0.2-0.1-0.1</td>\n",
       "      <td>0.100163</td>\n",
       "      <td>0.128770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.1-0.1-0.1-0.2-0.2-0.3</td>\n",
       "      <td>0.098629</td>\n",
       "      <td>0.128771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.1-0.1-0.2-0.4-0.1-0.1</td>\n",
       "      <td>0.092185</td>\n",
       "      <td>0.128791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.1-0.1-0.2-0.2-0.1-0.3</td>\n",
       "      <td>0.100319</td>\n",
       "      <td>0.128802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.1-0.2-0.2-0.2-0.1-0.2</td>\n",
       "      <td>0.100281</td>\n",
       "      <td>0.128807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.1-0.3-0.2-0.2-0.1-0.1</td>\n",
       "      <td>0.100250</td>\n",
       "      <td>0.128818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.2-0.1-0.2-0.1-0.2-0.2</td>\n",
       "      <td>0.097024</td>\n",
       "      <td>0.128830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.2-0.2-0.1-0.3-0.1-0.1</td>\n",
       "      <td>0.090711</td>\n",
       "      <td>0.128838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.2-0.1-0.1-0.3-0.1-0.2</td>\n",
       "      <td>0.090760</td>\n",
       "      <td>0.128846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.1-0.1-0.1-0.2-0.1-0.4</td>\n",
       "      <td>0.100460</td>\n",
       "      <td>0.128857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.1-0.2-0.1-0.2-0.1-0.3</td>\n",
       "      <td>0.100418</td>\n",
       "      <td>0.128860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.1-0.3-0.1-0.2-0.1-0.2</td>\n",
       "      <td>0.100382</td>\n",
       "      <td>0.128869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.1-0.2-0.1-0.4-0.1-0.1</td>\n",
       "      <td>0.092283</td>\n",
       "      <td>0.128870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.1-0.1-0.1-0.4-0.1-0.2</td>\n",
       "      <td>0.092333</td>\n",
       "      <td>0.128881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.1-0.4-0.1-0.2-0.1-0.1</td>\n",
       "      <td>0.100352</td>\n",
       "      <td>0.128883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.1-0.1-0.3-0.1-0.3-0.1</td>\n",
       "      <td>0.100808</td>\n",
       "      <td>0.128892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.2-0.2-0.1-0.1-0.2-0.2</td>\n",
       "      <td>0.097125</td>\n",
       "      <td>0.128895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.2-0.1-0.1-0.1-0.2-0.3</td>\n",
       "      <td>0.097173</td>\n",
       "      <td>0.128895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.1-0.1-0.1-0.3-0.2-0.2</td>\n",
       "      <td>0.094657</td>\n",
       "      <td>0.128910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.2-0.1-0.1-0.2-0.2-0.2</td>\n",
       "      <td>0.093111</td>\n",
       "      <td>0.128919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.1-0.2-0.2-0.1-0.3-0.1</td>\n",
       "      <td>0.100896</td>\n",
       "      <td>0.128947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.1-0.1-0.2-0.1-0.3-0.2</td>\n",
       "      <td>0.100941</td>\n",
       "      <td>0.128947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.2-0.1-0.4-0.1-0.1-0.1</td>\n",
       "      <td>0.098697</td>\n",
       "      <td>0.128953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.2-0.1-0.3-0.1-0.1-0.2</td>\n",
       "      <td>0.098803</td>\n",
       "      <td>0.128971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.3-0.1-0.3-0.1-0.1-0.1</td>\n",
       "      <td>0.093181</td>\n",
       "      <td>0.128975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.1-0.1-0.3-0.1-0.2-0.2</td>\n",
       "      <td>0.102583</td>\n",
       "      <td>0.128980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.2-0.2-0.3-0.1-0.1-0.1</td>\n",
       "      <td>0.098770</td>\n",
       "      <td>0.128980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.3-0.1-0.2-0.2-0.1-0.1</td>\n",
       "      <td>0.089192</td>\n",
       "      <td>0.129003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.2-0.1-0.2-0.1-0.1-0.3</td>\n",
       "      <td>0.098927</td>\n",
       "      <td>0.129004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.2-0.2-0.2-0.1-0.1-0.2</td>\n",
       "      <td>0.098890</td>\n",
       "      <td>0.129012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.1-0.2-0.1-0.1-0.3-0.2</td>\n",
       "      <td>0.101042</td>\n",
       "      <td>0.129015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.1-0.1-0.1-0.1-0.3-0.3</td>\n",
       "      <td>0.101092</td>\n",
       "      <td>0.129018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.1-0.3-0.1-0.1-0.3-0.1</td>\n",
       "      <td>0.100999</td>\n",
       "      <td>0.129018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.1-0.1-0.2-0.1-0.2-0.3</td>\n",
       "      <td>0.102710</td>\n",
       "      <td>0.129018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.3-0.1-0.2-0.1-0.1-0.2</td>\n",
       "      <td>0.093308</td>\n",
       "      <td>0.129019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.1-0.2-0.2-0.1-0.2-0.2</td>\n",
       "      <td>0.102670</td>\n",
       "      <td>0.129024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.2-0.1-0.2-0.1-0.3-0.1</td>\n",
       "      <td>0.095413</td>\n",
       "      <td>0.129034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.2-0.1-0.1-0.1-0.1-0.4</td>\n",
       "      <td>0.099068</td>\n",
       "      <td>0.129052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.2-0.2-0.1-0.1-0.1-0.3</td>\n",
       "      <td>0.099027</td>\n",
       "      <td>0.129058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.1-0.1-0.1-0.2-0.3-0.2</td>\n",
       "      <td>0.097087</td>\n",
       "      <td>0.129064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.2-0.3-0.1-0.1-0.1-0.2</td>\n",
       "      <td>0.098991</td>\n",
       "      <td>0.129069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.1-0.1-0.1-0.1-0.2-0.4</td>\n",
       "      <td>0.102854</td>\n",
       "      <td>0.129072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.3-0.2-0.1-0.2-0.1-0.1</td>\n",
       "      <td>0.089293</td>\n",
       "      <td>0.129075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.1-0.2-0.1-0.1-0.2-0.3</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>0.129076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.3-0.1-0.1-0.1-0.1-0.3</td>\n",
       "      <td>0.093455</td>\n",
       "      <td>0.129078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.3-0.1-0.1-0.2-0.1-0.2</td>\n",
       "      <td>0.089342</td>\n",
       "      <td>0.129080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.3-0.2-0.1-0.1-0.1-0.2</td>\n",
       "      <td>0.093410</td>\n",
       "      <td>0.129080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.1-0.3-0.1-0.1-0.2-0.2</td>\n",
       "      <td>0.102772</td>\n",
       "      <td>0.129085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.2-0.4-0.1-0.1-0.1-0.1</td>\n",
       "      <td>0.098963</td>\n",
       "      <td>0.129086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.3-0.3-0.1-0.1-0.1-0.1</td>\n",
       "      <td>0.093371</td>\n",
       "      <td>0.129088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.2-0.2-0.1-0.1-0.3-0.1</td>\n",
       "      <td>0.095515</td>\n",
       "      <td>0.129109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.2-0.1-0.1-0.1-0.3-0.2</td>\n",
       "      <td>0.095568</td>\n",
       "      <td>0.129116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.3-0.1-0.1-0.1-0.2-0.2</td>\n",
       "      <td>0.091717</td>\n",
       "      <td>0.129196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.1-0.1-0.2-0.1-0.4-0.1</td>\n",
       "      <td>0.099457</td>\n",
       "      <td>0.129254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.1-0.2-0.1-0.1-0.4-0.1</td>\n",
       "      <td>0.099559</td>\n",
       "      <td>0.129332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.1-0.1-0.1-0.1-0.4-0.2</td>\n",
       "      <td>0.099614</td>\n",
       "      <td>0.129341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.2-0.1-0.1-0.4-0.1-0.1</td>\n",
       "      <td>0.087031</td>\n",
       "      <td>0.129401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.1-0.1-0.4-0.1-0.1-0.2</td>\n",
       "      <td>0.104524</td>\n",
       "      <td>0.129438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.1-0.1-0.3-0.1-0.1-0.3</td>\n",
       "      <td>0.104628</td>\n",
       "      <td>0.129445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.1-0.2-0.4-0.1-0.1-0.1</td>\n",
       "      <td>0.104499</td>\n",
       "      <td>0.129454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.1-0.2-0.3-0.1-0.1-0.2</td>\n",
       "      <td>0.104599</td>\n",
       "      <td>0.129458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.1-0.1-0.2-0.1-0.1-0.4</td>\n",
       "      <td>0.104749</td>\n",
       "      <td>0.129466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.1-0.3-0.3-0.1-0.1-0.1</td>\n",
       "      <td>0.104575</td>\n",
       "      <td>0.129477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.1-0.2-0.2-0.1-0.1-0.3</td>\n",
       "      <td>0.104715</td>\n",
       "      <td>0.129478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.1-0.3-0.2-0.1-0.1-0.2</td>\n",
       "      <td>0.104687</td>\n",
       "      <td>0.129496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.1-0.1-0.1-0.1-0.1-0.5</td>\n",
       "      <td>0.104887</td>\n",
       "      <td>0.129504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.1-0.2-0.1-0.1-0.1-0.4</td>\n",
       "      <td>0.104848</td>\n",
       "      <td>0.129514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.3-0.1-0.1-0.3-0.1-0.1</td>\n",
       "      <td>0.085521</td>\n",
       "      <td>0.129520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.1-0.3-0.1-0.1-0.1-0.3</td>\n",
       "      <td>0.104815</td>\n",
       "      <td>0.129529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.1-0.4-0.1-0.1-0.1-0.2</td>\n",
       "      <td>0.104789</td>\n",
       "      <td>0.129550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.1-0.1-0.1-0.5-0.1-0.1</td>\n",
       "      <td>0.088699</td>\n",
       "      <td>0.129551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.4-0.2-0.1-0.1-0.1-0.1</td>\n",
       "      <td>0.088036</td>\n",
       "      <td>0.129580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.4-0.1-0.1-0.1-0.1-0.2</td>\n",
       "      <td>0.088085</td>\n",
       "      <td>0.129582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.3-0.1-0.1-0.1-0.3-0.1</td>\n",
       "      <td>0.090294</td>\n",
       "      <td>0.129691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.2-0.1-0.1-0.1-0.4-0.1</td>\n",
       "      <td>0.094271</td>\n",
       "      <td>0.129713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.1-0.1-0.1-0.2-0.4-0.1</td>\n",
       "      <td>0.095848</td>\n",
       "      <td>0.129732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.4-0.1-0.1-0.2-0.1-0.1</td>\n",
       "      <td>0.084176</td>\n",
       "      <td>0.129906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.1-0.1-0.1-0.1-0.5-0.1</td>\n",
       "      <td>0.098434</td>\n",
       "      <td>0.130039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lasso</td>\n",
       "      <td>0.118323</td>\n",
       "      <td>0.133198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ridge</td>\n",
       "      <td>0.118189</td>\n",
       "      <td>0.133623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.117566</td>\n",
       "      <td>0.133776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.080477</td>\n",
       "      <td>0.135540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lgb</td>\n",
       "      <td>0.104476</td>\n",
       "      <td>0.135992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.067421</td>\n",
       "      <td>0.139243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Name  Train Score  Valid Score\n",
       "31   0.1-0.1-0.3-0.3-0.1-0.1  0.095994     0.128519   \n",
       "46   0.1-0.2-0.2-0.3-0.1-0.1  0.096079     0.128575   \n",
       "25   0.1-0.1-0.2-0.3-0.1-0.2  0.096120     0.128576   \n",
       "74   0.2-0.1-0.3-0.2-0.1-0.1  0.094512     0.128612   \n",
       "40   0.1-0.2-0.1-0.3-0.1-0.2  0.096219     0.128645   \n",
       "54   0.1-0.3-0.1-0.3-0.1-0.1  0.096180     0.128647   \n",
       "15   0.1-0.1-0.1-0.3-0.1-0.3  0.096265     0.128648   \n",
       "71   0.2-0.1-0.2-0.2-0.1-0.2  0.094639     0.128663   \n",
       "82   0.2-0.2-0.2-0.2-0.1-0.1  0.094599     0.128664   \n",
       "24   0.1-0.1-0.2-0.2-0.2-0.2  0.098481     0.128700   \n",
       "79   0.2-0.2-0.1-0.2-0.1-0.2  0.094739     0.128728   \n",
       "64   0.2-0.1-0.1-0.2-0.1-0.3  0.094785     0.128729   \n",
       "85   0.2-0.3-0.1-0.2-0.1-0.1  0.094700     0.128733   \n",
       "33   0.1-0.1-0.4-0.2-0.1-0.1  0.100090     0.128738   \n",
       "72   0.2-0.1-0.2-0.3-0.1-0.1  0.090611     0.128762   \n",
       "30   0.1-0.1-0.3-0.2-0.1-0.2  0.100195     0.128763   \n",
       "39   0.1-0.2-0.1-0.2-0.2-0.2  0.098581     0.128768   \n",
       "48   0.1-0.2-0.3-0.2-0.1-0.1  0.100163     0.128770   \n",
       "12   0.1-0.1-0.1-0.2-0.2-0.3  0.098629     0.128771   \n",
       "26   0.1-0.1-0.2-0.4-0.1-0.1  0.092185     0.128791   \n",
       "23   0.1-0.1-0.2-0.2-0.1-0.3  0.100319     0.128802   \n",
       "45   0.1-0.2-0.2-0.2-0.1-0.2  0.100281     0.128807   \n",
       "56   0.1-0.3-0.2-0.2-0.1-0.1  0.100250     0.128818   \n",
       "69   0.2-0.1-0.2-0.1-0.2-0.2  0.097024     0.128830   \n",
       "80   0.2-0.2-0.1-0.3-0.1-0.1  0.090711     0.128838   \n",
       "66   0.2-0.1-0.1-0.3-0.1-0.2  0.090760     0.128846   \n",
       "11   0.1-0.1-0.1-0.2-0.1-0.4  0.100460     0.128857   \n",
       "38   0.1-0.2-0.1-0.2-0.1-0.3  0.100418     0.128860   \n",
       "53   0.1-0.3-0.1-0.2-0.1-0.2  0.100382     0.128869   \n",
       "41   0.1-0.2-0.1-0.4-0.1-0.1  0.092283     0.128870   \n",
       "17   0.1-0.1-0.1-0.4-0.1-0.2  0.092333     0.128881   \n",
       "59   0.1-0.4-0.1-0.2-0.1-0.1  0.100352     0.128883   \n",
       "29   0.1-0.1-0.3-0.1-0.3-0.1  0.100808     0.128892   \n",
       "77   0.2-0.2-0.1-0.1-0.2-0.2  0.097125     0.128895   \n",
       "61   0.2-0.1-0.1-0.1-0.2-0.3  0.097173     0.128895   \n",
       "16   0.1-0.1-0.1-0.3-0.2-0.2  0.094657     0.128910   \n",
       "65   0.2-0.1-0.1-0.2-0.2-0.2  0.093111     0.128919   \n",
       "44   0.1-0.2-0.2-0.1-0.3-0.1  0.100896     0.128947   \n",
       "21   0.1-0.1-0.2-0.1-0.3-0.2  0.100941     0.128947   \n",
       "75   0.2-0.1-0.4-0.1-0.1-0.1  0.098697     0.128953   \n",
       "73   0.2-0.1-0.3-0.1-0.1-0.2  0.098803     0.128971   \n",
       "94   0.3-0.1-0.3-0.1-0.1-0.1  0.093181     0.128975   \n",
       "28   0.1-0.1-0.3-0.1-0.2-0.2  0.102583     0.128980   \n",
       "83   0.2-0.2-0.3-0.1-0.1-0.1  0.098770     0.128980   \n",
       "93   0.3-0.1-0.2-0.2-0.1-0.1  0.089192     0.129003   \n",
       "68   0.2-0.1-0.2-0.1-0.1-0.3  0.098927     0.129004   \n",
       "81   0.2-0.2-0.2-0.1-0.1-0.2  0.098890     0.129012   \n",
       "36   0.1-0.2-0.1-0.1-0.3-0.2  0.101042     0.129015   \n",
       "8    0.1-0.1-0.1-0.1-0.3-0.3  0.101092     0.129018   \n",
       "52   0.1-0.3-0.1-0.1-0.3-0.1  0.100999     0.129018   \n",
       "20   0.1-0.1-0.2-0.1-0.2-0.3  0.102710     0.129018   \n",
       "92   0.3-0.1-0.2-0.1-0.1-0.2  0.093308     0.129019   \n",
       "43   0.1-0.2-0.2-0.1-0.2-0.2  0.102670     0.129024   \n",
       "70   0.2-0.1-0.2-0.1-0.3-0.1  0.095413     0.129034   \n",
       "60   0.2-0.1-0.1-0.1-0.1-0.4  0.099068     0.129052   \n",
       "76   0.2-0.2-0.1-0.1-0.1-0.3  0.099027     0.129058   \n",
       "13   0.1-0.1-0.1-0.2-0.3-0.2  0.097087     0.129064   \n",
       "84   0.2-0.3-0.1-0.1-0.1-0.2  0.098991     0.129069   \n",
       "7    0.1-0.1-0.1-0.1-0.2-0.4  0.102854     0.129072   \n",
       "96   0.3-0.2-0.1-0.2-0.1-0.1  0.089293     0.129075   \n",
       "35   0.1-0.2-0.1-0.1-0.2-0.3  0.102810     0.129076   \n",
       "87   0.3-0.1-0.1-0.1-0.1-0.3  0.093455     0.129078   \n",
       "90   0.3-0.1-0.1-0.2-0.1-0.2  0.089342     0.129080   \n",
       "95   0.3-0.2-0.1-0.1-0.1-0.2  0.093410     0.129080   \n",
       "51   0.1-0.3-0.1-0.1-0.2-0.2  0.102772     0.129085   \n",
       "86   0.2-0.4-0.1-0.1-0.1-0.1  0.098963     0.129086   \n",
       "97   0.3-0.3-0.1-0.1-0.1-0.1  0.093371     0.129088   \n",
       "78   0.2-0.2-0.1-0.1-0.3-0.1  0.095515     0.129109   \n",
       "62   0.2-0.1-0.1-0.1-0.3-0.2  0.095568     0.129116   \n",
       "88   0.3-0.1-0.1-0.1-0.2-0.2  0.091717     0.129196   \n",
       "22   0.1-0.1-0.2-0.1-0.4-0.1  0.099457     0.129254   \n",
       "37   0.1-0.2-0.1-0.1-0.4-0.1  0.099559     0.129332   \n",
       "9    0.1-0.1-0.1-0.1-0.4-0.2  0.099614     0.129341   \n",
       "67   0.2-0.1-0.1-0.4-0.1-0.1  0.087031     0.129401   \n",
       "32   0.1-0.1-0.4-0.1-0.1-0.2  0.104524     0.129438   \n",
       "27   0.1-0.1-0.3-0.1-0.1-0.3  0.104628     0.129445   \n",
       "49   0.1-0.2-0.4-0.1-0.1-0.1  0.104499     0.129454   \n",
       "47   0.1-0.2-0.3-0.1-0.1-0.2  0.104599     0.129458   \n",
       "19   0.1-0.1-0.2-0.1-0.1-0.4  0.104749     0.129466   \n",
       "57   0.1-0.3-0.3-0.1-0.1-0.1  0.104575     0.129477   \n",
       "42   0.1-0.2-0.2-0.1-0.1-0.3  0.104715     0.129478   \n",
       "55   0.1-0.3-0.2-0.1-0.1-0.2  0.104687     0.129496   \n",
       "6    0.1-0.1-0.1-0.1-0.1-0.5  0.104887     0.129504   \n",
       "34   0.1-0.2-0.1-0.1-0.1-0.4  0.104848     0.129514   \n",
       "91   0.3-0.1-0.1-0.3-0.1-0.1  0.085521     0.129520   \n",
       "50   0.1-0.3-0.1-0.1-0.1-0.3  0.104815     0.129529   \n",
       "58   0.1-0.4-0.1-0.1-0.1-0.2  0.104789     0.129550   \n",
       "18   0.1-0.1-0.1-0.5-0.1-0.1  0.088699     0.129551   \n",
       "100  0.4-0.2-0.1-0.1-0.1-0.1  0.088036     0.129580   \n",
       "98   0.4-0.1-0.1-0.1-0.1-0.2  0.088085     0.129582   \n",
       "89   0.3-0.1-0.1-0.1-0.3-0.1  0.090294     0.129691   \n",
       "63   0.2-0.1-0.1-0.1-0.4-0.1  0.094271     0.129713   \n",
       "14   0.1-0.1-0.1-0.2-0.4-0.1  0.095848     0.129732   \n",
       "99   0.4-0.1-0.1-0.2-0.1-0.1  0.084176     0.129906   \n",
       "10   0.1-0.1-0.1-0.1-0.5-0.1  0.098434     0.130039   \n",
       "4    lasso                    0.118323     0.133198   \n",
       "3    ridge                    0.118189     0.133623   \n",
       "1    linear                   0.117566     0.133776   \n",
       "2    xgb                      0.080477     0.135540   \n",
       "5    lgb                      0.104476     0.135992   \n",
       "0    rf                       0.067421     0.139243   "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_dict = {'Name': name_list, 'Train Score' : train_score_list, 'Valid Score': valid_score_list}\n",
    "\n",
    "metric_data = pd.DataFrame(data = metric_dict)\n",
    "metric_data.sort_values(by=['Valid Score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Transform Testing Data and get Testing Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a found the model we want to use its time to import our testing data and transform it to match the format of our cleaned training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = 'test.csv'\n",
    "df = pd.read_csv(data_location, low_memory=False)\n",
    "df=df.set_index('Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_num={'MSSubClass': 50.0,\n",
    " 'LotFrontage': 69.0,\n",
    " 'LotArea': 9478.5,\n",
    " 'OverallQual': 6.0,\n",
    " 'OverallCond': 5.0,\n",
    " 'YearBuilt': 1973.0,\n",
    " 'YearRemodAdd': 1994.0,\n",
    " 'MasVnrArea': 0.0,\n",
    " 'BsmtFinSF1': 383.5,\n",
    " 'BsmtFinSF2': 0.0,\n",
    " 'BsmtUnfSF': 477.5,\n",
    " 'TotalBsmtSF': 991.5,\n",
    " '1stFlrSF': 1087.0,\n",
    " '2ndFlrSF': 0.0,\n",
    " 'LowQualFinSF': 0.0,\n",
    " 'GrLivArea': 1464.0,\n",
    " 'BsmtFullBath': 0.0,\n",
    " 'BsmtHalfBath': 0.0,\n",
    " 'FullBath': 2.0,\n",
    " 'HalfBath': 0.0,\n",
    " 'BedroomAbvGr': 3.0,\n",
    " 'KitchenAbvGr': 1.0,\n",
    " 'TotRmsAbvGrd': 6.0,\n",
    " 'Fireplaces': 1.0,\n",
    " 'GarageYrBlt': 1980.0,\n",
    " 'GarageCars': 2.0,\n",
    " 'GarageArea': 480.0,\n",
    " 'WoodDeckSF': 0.0,\n",
    " 'OpenPorchSF': 25.0,\n",
    " 'EnclosedPorch': 0.0,\n",
    " '3SsnPorch': 0.0,\n",
    " 'ScreenPorch': 0.0,\n",
    " 'PoolArea': 0.0,\n",
    " 'MiscVal': 0.0,\n",
    " 'MoSold': 6.0,\n",
    " 'YrSold': 2008.0,\n",
    " 'TotalSF': 2474.0,\n",
    " 'TotalBath': 2.0,\n",
    " 'SalePrice': 163000.0}\n",
    "\n",
    "df = df.fillna(replace_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_val={'MasVnrType':'None','BsmtFinType1':'NoBas','BsmtFinType2':'NoBas','BsmtCond':'NoBas', 'BsmtExposure': 'NoBas',\n",
    "         'Electrical':'Sbrkr','FireplaceQu':'NoFp','GarageType':'NoGar','GarageFinish':'NoGar','GarageQual':'NoGar','GarageCond':'NoGar',\n",
    "         'PoolQC':'NoP','Fence':'NoF','BsmtQual':'NoBas','KitchenQual' : 'TA', 'GarageQual': 'TA' }\n",
    "\n",
    "df= df.fillna(repl_val)\n",
    "\n",
    "df['TotalSF'] = df['TotalBsmtSF'] + df['1stFlrSF'] + df['2ndFlrSF'] \n",
    "\n",
    "df['TotalBath'] = .5 *(df['HalfBath'] + df['BsmtHalfBath']) + df['FullBath'] + df['BsmtFullBath']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ohe = ['Neighborhood', 'HouseStyle', 'Foundation','GarageType'] \n",
    "cols = ['ExterQual', 'BsmtQual', 'BsmtExposure', 'KitchenQual', 'GarageFinish', 'OverallQual', 'YearBuilt', 'MasVnrArea',\n",
    "        'GrLivArea', 'TotRmsAbvGrd', 'Fireplaces', 'GarageArea', 'TotalSF', 'TotalBath']\n",
    "\n",
    "replace= {'ExterQual':{'Ex':7,'Fa':2,'Gd':5,'TA':3,'Po':1},'BsmtQual':{'Ex':6,'Fa':2,'Gd':4,'TA':3,'Po':1,'NoBas':2},\n",
    "          'BsmtExposure':{'No':3,'Gd':5,'Mn':4,'Av':4,'NoBas':2},'KitchenQual':{'TA':3,'Gd':4,'Ex':6,'Fa':2,'Po':1},\n",
    "           'FireplaceQu':{'TA':2,'Gd':2.2,'Ex':3.3,'Fa':1.6,'Po':1.2,'NoFp':1.4},'GarageFinish': {'RFn':4,'Unf':3,'Fin':5,'NoGar':2}}\n",
    "\n",
    "df_cleaned = df[cols].replace(replace)\n",
    "\n",
    "df_cleaned['YearBuilt']=2020-df_cleaned['YearBuilt']\n",
    "\n",
    "\n",
    "df_cleaned_dummy= pd.get_dummies(df[cols_ohe])\n",
    "df_cleaned_dummy['HouseStyle_2.5Fin'] = 0\n",
    "\n",
    "df_cleaned = pd.concat([df_cleaned,df_cleaned_dummy],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_2 = {'OverallCond': {1:1, 2:1, 3:1, 4:2, 5:2, 6:2, 7:3, 8:3, 9:3, 10:3}, \n",
    "           'GarageQual': {'TA': 1, 'Gd': 2, 'Fa': 1, 'Ex': 3,'Po': 1}}\n",
    "            \n",
    "new_cols = ['OverallCond', 'GarageQual']\n",
    "\n",
    "df_add = df[new_cols]\n",
    "\n",
    "df_add = df_add.fillna({'OverallCond' : 5, 'GarageQual': 'NoGar'})\n",
    "\n",
    "df_add['CommerZone']=0\n",
    "df_add.loc[df['MSZoning'] == 'C','CommerZone']=1\n",
    "\n",
    "\n",
    "for i  in (replace_2.keys()):\n",
    "    df_add[i] = df_add[i].map(replace_2[i])\n",
    "\n",
    " \n",
    "df_testing = pd.concat([df_cleaned, df_add], axis=1)\n",
    "\n",
    "for j in ['MasVnrArea','GrLivArea','GarageArea','TotalSF']:\n",
    "    df_testing.loc[:,j] = np.log1p(df_testing[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testing = df_testing[df_X.columns]\n",
    "df_testing['ExterQual']=df_testing['ExterQual'].astype('int32')\n",
    "df_testing['KitchenQual']=df_testing['KitchenQual'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will now fit the data to our entire labelled dataset. Then we use use it to predict the unlabeled test data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.06, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=550, n_jobs=-1, num_leaves=3, objective=None,\n",
       "       random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(df_X, df_y) \n",
    "ridge.fit(df_X,df_y)\n",
    "xgb.fit(df_X,df_y)\n",
    "linear.fit(df_X,df_y)\n",
    "lasso.fit(df_X,df_y)\n",
    "lgb.fit(df_X,df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = [train_pred_rf, train_pred_ridge, train_pred_linear, train_pred_xgb, train_pred_lgb, train_pred_lasso]\n",
    "percentage_list = [.1, .1, .3, .3, .1, .1]\n",
    "\n",
    "test_pred = (.1 * rf.predict(df_testing) + .1 * ridge.predict(df_testing) + .3 * linear.predict(df_testing) +\n",
    "             .3 * xgb.predict(df_testing) + .1 * lgb.predict(df_testing) + .1 * lasso.predict(df_testing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testing_y = np.expm1(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(data =\n",
    "                     {'Id' : df_testing.index.values, 'SalePrice': testing_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all that is left to do is upload the results to the kaggle competition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
